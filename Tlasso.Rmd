---
title: "Tlasso"
date: "27/09/2023"
output: html_document
---

```{r, setup, include=FALSE}
knitr::opts_knit$set(root.dir = "G:/Il mio Drive/Eugenia's Thesis/Data")
```

EBIC evaluation functions

```{r functions, include=TRUE,echo=TRUE, eval=TRUE,cache=TRUE}

ebic_eval <- function(Y, n, beta0, ebic.gamma, edge.tol, tol, v, stop_crit){
  res <- tlasso(Y, beta0, v, stop_crit)
  S <- res$psi  ## dmvt has symmetric matrix problems
  K <- pd.solve(S)
  p <- ncol(Y)
  log_likelihood_t <- sum(dmvt(Y, rep(0, p), sigma = S, v, log = TRUE))
  KR <- stats::cov2cor((K))         #to make edge count independend of scalings
  nedg <- length(which(abs(KR[upper.tri(abs(KR), diag = FALSE)]) > edge.tol))
  ebic <- -(2)*log_likelihood_t  + nedg * (log(n) + 4 * ebic.gamma * log(p))
  return(ebic)   
}

ebic_eval_BayesOpt <- function(Y, n, beta0, ebic.gamma, edge.tol, tol, v, stop_crit){
  ebic <- ebic_eval(Y, n, beta0, ebic.gamma, edge.tol, tol, v, stop_crit)
  return(list("Score" = -ebic, "Pred" = 0))   
}

ebic_eval_network <- function(n, R, A, beta0, beta1, ebic.gamma, edge.tol, tol){
  U <- exp(beta0 + beta1*A)   
  diag(U) <- 0
  return(ebic_eval(n, R, U, ebic.gamma, edge.tol, tol))
}

ebic_eval_two_networks <- function(n, R, A1, A2, beta0, beta1, beta2, ebic.gamma, edge.tol, tol){
  U <- exp(beta0 + beta1*A1 + beta2*A2)  
  diag(U) <- 0
  return(ebic_eval(n, R, U, ebic.gamma, edge.tol, tol))
}

ebic_eval_network_BayesOpt <- function(n, R, A, beta0, beta1, ebic.gamma, edge.tol, tol){
  U <- exp(beta0 + beta1*A)           #### remember a = beta1, b= beta0
  #U <- exp(beta0)*(1 - A) + exp(beta1)*A
  diag(U) <- 0
  ebic <- ebic_eval(n, R, U, ebic.gamma, edge.tol, tol)
  return(list("Score" = -ebic, "Pred" = 0))
}

ebic_eval_two_networks_BayesOpt <- function(n, R, A1, A2, beta0, beta1, beta2, ebic.gamma, edge.tol, tol){
  U <- exp(beta0 + beta1*A1 + beta2*A2)           #### remember a = beta1, b= beta0
  diag(U) <- 0
  try(ebic <- ebic_eval(n, R, U, ebic.gamma, edge.tol, tol))
  return(list("Score" = -ebic, "Pred" = 0))
}

standardise_network_matrix_tri <- function(A) {
  p <- nrow(A)
  A_tri <- A[upper.tri(A)]
  bar_A_tri <- mean(A_tri)
  S2_A_tri <- 1/length(A_tri)*sum((A_tri - bar_A_tri)^2)
  
  return((A - bar_A_tri)/sqrt(S2_A_tri))
}

## Turning the correlation matrix given by the golazo function back to a covariance matrix, useful in out-of-sample-llh
cor2cov <- function(Theta_cor, sigma2_vect){
  # Theta_cor is correlation matrix, sqrt(sigma2_vect) is the standard deviations of each variable
  p <- nrow(Theta_cor)
  Theta_cov <- matrix(NA, nrow = p, ncol = p)
  for(i in 1:p){
    Theta_cov[, i] <- Theta_cor[,i]*sqrt(sigma2_vect[i])*sqrt(sigma2_vect)   
  }
  return(Theta_cov)
}

threshold <- function(Rho_mat, threshold){
  return(Rho_mat*(abs(Rho_mat) >= threshold))
}

# No Network matrix
beta0_max_TLASSO <- function(R){
  return(log(max(abs(R - diag(diag(R))))))## check we can irgnore diags
  #return(log(max(max(diag(R)^2) - abs(R)))) ## Piotr's updated bound!
}

```

Hyparameters

```{r hyperparameters, include=TRUE,echo=TRUE, eval=TRUE,cache=TRUE}

ebic.gamma <- 0           # set to zero to get BIC
edge.tol <-  1e-6         # be consistent with GLASSO+EBIC method

```

Packages

```{r packages, include=TRUE,echo=TRUE, eval=TRUE,cache=FALSE}

library(golazo)
library(mvtnorm)
library(graphics)
#install.packages("NMOF")
library(NMOF)
library(rBayesianOptimization)
#install.packages("metRology")
library(metRology)
library(matrixStats)
library(mnormt)
library(PerformanceAnalytics)

```

Loading data (log-return in %) from 1984 to 2016

```{r loading data}

sp500_CIK <- read.csv("SP500_new.csv")

```

Extracting years of interest and keeping only the stocks always present over those years

```{r clearing data}

start_year = 1985
end_year = 2016

data <- sp500_CIK[sp500_CIK$Year %in% (start_year:end_year),]

#vector of row coordinates of the first observation per year (1985-2015)
i <- c(1,253,506,759,1012,1264,1517,1770,2024,2278,2529,2781,3035,3288,3540,3792,4044,4292,4544,4796,5048,5300,5551,5802,6055,6307,6559,6811,7061,7313,7565)

#vector of row coordinates of the last observation per year (1986-2016)
j <- c(505,758,1011,1263,1516,1769,2023,2276,2528,2780,3034,3287,3539,3791,4043,4291,4543,4795,5047,5299,5550,5801,6054,6306,6558,6810,7060,7312,7564,7816,7895)

to_keep <- list()
for (k in 1:length(j)){
  #we only keep companies that are present over 2 consecutive years
  to_keep[[k]] = apply(data[i[k]:j[k],],2,function(x) all(!is.na(x)))
}

Y <- list()
for (k in 1:length(j)){
  Y[[k]] = data[,to_keep[[k]]]
}

end_year=2015 #last year the model is fitted in

Y_repeats = list()
Y_test <- list()
k <- seq(from =1 , to = length(j), by = 1)
t <- seq(from = start_year, to = end_year, by = 1)
#create a list in which each object corresponds to a year and it is a matrix n (number of days) x p (number of stocks)
for (k in 1:length(k)){
  Y_test[[k]] <- Y[[k]][Y[[k]]$Year == t[k],-(2)]
  Y_repeats[[k]] = Y[[k]][Y[[k]]$Year == t[k],-(1:2)]
}

```

Tlasso 

```{r Tlasso}

tlasso <- function(Y, beta0_TLASSO, v, stop_crit){
  
  ##defining parameters##
  p = ncol(Y)
  Y_sd <- apply(Y, 2, sd)
  Y <- Y%*%diag(1/Y_sd)
  #creating a list of matrices psi to be filled at each iteration
  psi <- list()
  psi[[1]] <- diag(diag(cov(Y))) #initial value of psi
  #creating a list vectors mu to be filled at each iteration
  mu <- list()
  mu[[1]] <- rep(0,p) #initial value of mu
  n = nrow(Y) 
  delta <- rep(NA, n)
  L <- matrix(-1,p,p) 
  U <- matrix (1,p,p)
  diag(U) <- diag(L) <- 0
  
  ###EM algorithm###
  t <- 1 
  STOP <- FALSE
  while(!STOP) {
    
    t <- t + 1
    
    ##E_step##
    for (i in 1:n){
      delta[i] <- t(Y[i,]-mu[[t-1]])%*%(solve(psi[[t-1]]))%*%(Y[i,]-mu[[t-1]])   
    }
    
    tau <- (v+p)/(v+delta)   
    
    mut <- rep(0,p)
    for (i in 1:n){
      mut <- mut+((tau[i])*(Y[i,])/sum(tau))
    }
    mu[[t]] <- mut
    
    S <- matrix(0,p,p)
    for (i in 1:n){
      S <- S+tau[i]*(Y[i,]-mu[[t]])%*%t(Y[i,]-mu[[t]])/n
    }
    
    
    ##M_step##
    R <- S
    GraphicalModel_TLASSO <- golazo (R, L = exp(beta0_TLASSO) * L, U =exp(beta0_TLASSO)* U, tol = 1e-6, verbose=FALSE)
    
    ##Updating psi and mu##
    psi[[t]] <- GraphicalModel_TLASSO$Sig
    
    
    ##stop criteria##
    print(paste0("Iter: ",t," - tol: ", max(abs(psi[[t]] - psi[[t-1]]))))
    
    if(max(abs(psi[[t]] - psi[[t-1]])) < stop_crit){
      STOP <- TRUE
    }
  }
  psi[[t]] <- cor2cov(psi[[t]], sigma2_vect = Y_sd^2)
  psi[[t]] <- (psi[[t]]+t(psi[[t]]))/2
  return(list(psi = psi[[t]], R = R, S = S))
}

```

TLASSO

```{r TLASSO_run, include=TRUE,echo=TRUE, eval=TRUE,cache=TRUE}

N <- length(Y_repeats)

beta0_grid_length <- 10
beta0_grid_min <- -4
beta0_grid_max <- rep(NA,N)

R <- list()

beta_optimise <- list()
beta0_TLASSO <- rep(NA,N)
ebic_eval_optim_TLASSO <- rep(NA, N)

GraphicalModel <- list()
Rho_hat_TLASSO <- list()

for (k in 1:N){
  n = nrow(Y_repeats[[k]])
  
  #grid-search
  beta0_grid_max[k] <- beta0_max_TLASSO(cov(Y_repeats[[k]]))
  
  #BayesOpt 
  beta_optimise[[k]] <- BayesianOptimization(
    FUN = function(beta0){ebic_eval_BayesOpt(Y = lapply(Y_repeats, function(df) as.matrix(df))[[k]], n, beta0, ebic.gamma = ebic.gamma, edge.tol = edge.tol, tol = 1e-6, v=5, stop_crit=1e-3)},
    bounds = list(beta0 = c(beta0_grid_min, beta0_grid_max[k])),
    init_points = 5,
    n_iter = beta0_grid_length,
    acq = "ucb", 
    kernel = list(type = "exponential", power = 2),
  )
  
  beta0_TLASSO[k] <- beta_optimise[[k]]$Best_Par
  ebic_eval_optim_TLASSO[k] <- - beta_optimise[[k]]$Best_Value
  
  #Using the optimal beta0 
  GraphicalModel[[k]] <- tlasso (Y = as.matrix(Y_repeats[[k]]), beta0_TLASSO[k], v = 5, stop_crit = 1e-3)
  
  Rho_hat_TLASSO[[k]] <- threshold(cov2cor(pd.solve(GraphicalModel[[k]]$psi)), edge.tol)
  
}

```

Analysis

```{r Analysis, include=TRUE,echo=TRUE, eval=TRUE,cache=FALSE}

beta0_TLASSO 

ebic_eval_optim_TLASSO

n_edges_TLASSO <- rep(NA,N)
for (k in 1:N){
  n_edges_TLASSO[k] <- sum(Rho_hat_TLASSO[[k]][lower.tri((Rho_hat_TLASSO[[k]]))] != 0)
}

```

Minimum Variance function

```{r Minimum-Variance functions, include=TRUE,echo=TRUE, eval=TRUE,cache=FALSE}

minimum_variance_portfolio <- function (cov.Rt){
  one.vec <- rep(1,nrow(cov.Rt))
  num <- solve(cov.Rt) %*% one.vec
  den <- as.numeric(t(one.vec) %*% num)
  return(num/den)
}

```

Expected return function

```{r Expected Return function, include=TRUE,echo=TRUE, eval=TRUE,cache=FALSE}

expected_return_portfolio_minimum_variance <- function (cov.Rt, mean){
  one.vec <- rep(1,nrow(cov.Rt))
  num <- as.numeric(t(one.vec) %*% solve(cov.Rt) %*% mean)
  den <- as.numeric(t(one.vec) %*% solve(cov.Rt) %*% one.vec)
  return(num/den)
}

```

Defining baseline (equally weighted stocks)

```{r Defining baseline, include=TRUE,echo=TRUE, eval=TRUE,cache=FALSE}

p <- vector() 
for (k in 1:N){
  p[k] <- ncol(Y_repeats[[k]]) #every year we have a different number of stocks (portfolio changes)
}

mean <- list()
for (k in 1:N){
  mean[[k]] <- colMeans(Y_repeats[[k]])
}

weights_b <- list()
for (k in 1:N){
  weights_b[[k]] <- rep(1/p[k],p[k])
}

#the baseline is the target return rate for the mean variance portfolio  
baseline_portfolio <- rep(NA,N)   
for (k in 1:N){
  baseline_portfolio[k] <- sum(mean[[k]] %*% weights_b[[k]])
}

```

##Estimating Sigma with TLASSO

```{r estimating Sigma with TLASSO, include=TRUE,echo=TRUE, eval=TRUE,cache=FALSE}

v = 5 #degrees of freedom

Sigma_hat_TLASSO <- list()   #N pxp matrices where p changes according to the year
for (k in 1:N){
  Sigma_hat_TLASSO[[k]] <- (cor2cov(Rho_hat_TLASSO[[k]], sigma2_vect = (apply(lapply(Y_repeats, function(df) as.matrix(df))[[k]], 2, sd))^2))*(v/(v-2))
}

```


Estimating weights

```{r Weights, include=TRUE,echo=TRUE, eval=TRUE,cache=FALSE}

#minimum variance
weights_minimum_variance_TLASSO <- list()
for (k in 1:N){
  weights_minimum_variance_TLASSO[[k]] <- minimum_variance_portfolio(Sigma_hat_TLASSO[[k]]) 
}

for (k in 1:N){
  weights_minimum_variance_TLASSO[[k]] <- weights_minimum_variance_TLASSO[[k]]/sum(weights_minimum_variance_TLASSO[[k]])
}

#mean variance
weights_mean_variance_TLASSO <- list()
for (k in 1:N){
  weights_mean_variance_TLASSO[[k]] <- mvPortfolio(mean[[k]], Sigma_hat_TLASSO[[k]], min.return=baseline_portfolio[k])
}

```

Estimating expected return portfolio

```{r Expected return portfolio, include=TRUE,echo=TRUE, eval=TRUE,cache=FALSE}

#minimum variance
expected_return_portfolio_minimum_variance_TLASSO <- rep(NA,N)
for (k in 1:N){
  expected_return_portfolio_minimum_variance_TLASSO[k] <- expected_return_portfolio_minimum_variance(Sigma_hat_TLASSO[[k]], mean[[k]])
}

#mean variance
expected_return_portfolio_mean_variance_TLASSO <- rep(NA,N)
for (k in 1:N){
  expected_return_portfolio_mean_variance_TLASSO[k] <- sum(weights_mean_variance_TLASSO[[k]]*mean[[k]])
}


```

Two portfolio solution

```{r Two portfolio solution, include=TRUE,echo=TRUE, eval=TRUE,cache=FALSE}

#it makes the expected return portfolio equal to the baseline we defined before 

W_mk <- list()
for (k in 1:N){
  one.vec <- rep(1,nrow(Sigma_hat_TLASSO[[k]]))
  W_mk[[k]] <- (mean[[k]]%*%solve(Sigma_hat_TLASSO[[k]]))/(as.numeric(t(one.vec[k]) %*% mean[[k]] %*% solve(Sigma_hat_TLASSO[[k]])))
}

v_2PS_TLASSO <- list()
for (k in 1:N){
  v_2PS_TLASSO[[k]] <- weights_mean_variance_TLASSO[[k]]-weights_minimum_variance_TLASSO[[k]]
}

alpha_2PS_TLASSO <- rep(NA,N)
for (k in 1:N){
  alpha_2PS_TLASSO[k] <- ((sum(mean[[k]])/p[k])-(t(mean[[k]]) %*% weights_minimum_variance_TLASSO[[k]]))/(t(mean[[k]]) %*% v_2PS_TLASSO[[k]])
}

w_2PS_TLASSO <- list()
for (k in 1:N){
  w_2PS_TLASSO[[k]] <- weights_minimum_variance_TLASSO[[k]]+(v_2PS_TLASSO[[k]]*alpha_2PS_TLASSO[k])
}

expected_return_portfolio_2PS_TLASSO <- rep(NA,N)
for (k in 1:N){
  expected_return_portfolio_2PS_TLASSO[k] <- t(mean[[k]])%*%w_2PS_TLASSO[[k]]
}

```

Plot Sigma and Rho matrices

```{r Plot Sigma and Rho matrices, include=TRUE,echo=TRUE, eval=TRUE,cache=FALSE}

matrixplot = function(m) {
  require(ggplot2)
  require(reshape2)
  
  p = nrow(m)
  
  m.mat = data.frame(Var1=rep(1:p,p),
                     Var2=rep(1:p,each=p),
                     Theta=as.vector(t(m)[,p:1]))
  
  pl = ggplot() + 
    geom_tile(data = m.mat, aes(x=Var1, y=as.numeric(Var2), fill=Theta)) + ylab('') + xlab('') +
    scale_fill_gradient2(low="red",high="blue",mid="white",midpoint=0) +
    geom_rect(aes(ymin=0.5,ymax=p+0.5,xmin=0.5,xmax=p+0.5),col="black",fill=NA,linetype='dashed') +
    theme(panel.grid = element_blank(), 
          panel.background = element_rect(fill='white'),
          plot.background = element_rect(color=NA), 
          axis.title.x=element_blank(), 
          axis.title.y=element_blank(),
          axis.ticks=element_blank(),
          axis.text=element_blank(),
          text = element_text(size=20), 
          legend.position = "right") 
  
  plot(pl)
}

for (k in 1:N){
  matrixplot(Sigma_hat_TLASSO[[k]]-diag(NA,p[k]))
  matrixplot(Rho_hat_TLASSO[[k]]-diag(NA,p[k]))
}

```

Loading Fama and French data 

```{r loading Fama and French data}

FF <- read.delim2('F-F_Research_Data_Factors_daily.txt',dec='.')

data_FF <- FF[FF$Year %in% (start_year:end_year),]

FF_repeats = list()
it = 0
for (t in start_year:end_year) {
  it = it+1
  FF_year = data_FF[data_FF$Year == t,-(1:2)]
  FF_repeats[[it]] = FF_year
}

```

Fitting Fama and French regression model and getting fitted values

```{r Fitting Fama and French model}

FF_regression <-list()
fitted_FF <- list()

for (k in 1:N){
  Y_year = Y_repeats[[k]]
  n <- nrow(Y_year)
  fitted_FF[[k]] = matrix(NA,n,p[k])
  for (i in 1:p[k])  {
    fitted_FF[[k]][,i] <- lm((Y_year[,i]-FF_repeats[[k]][[4]])~FF_repeats[[k]][[2]]+FF_repeats[[k]][[3]]+FF_repeats[[k]][[1]])$fitted
  }
  FF_regression[[k]] = fitted_FF[[k]]
}

```

Daily excess returns (residuals of the regression)

```{r Daily excess returns }

Y_repeats_FF <- list()
for (k in 1:N){
  for (i in 1:p[k]) {
    Y_repeats_FF[[k]] <- Y_repeats[[k]]-FF_regression[[k]][,i]
  }}

```

TLASSO FF

```{r TLASSO_run, include=TRUE,echo=TRUE, eval=TRUE,cache=TRUE}

N <- length(Y_repeats_FF)

beta0_grid_length <- 10
beta0_grid_min <- -4
beta0_grid_max <- rep(NA,N)

R <- list()

beta_optimise <- list()
beta0_TLASSO_FF <- rep(NA,N)

ebic_eval_optim_TLASSO_FF <- rep(NA, N)

GraphicalModel <- list()
Rho_hat_TLASSO_FF <- list()

for (k in 1:N){
  n = nrow(Y_repeats_FF[[k]])
  
  #grid-search
  beta0_grid_max[k] <- beta0_max_TLASSO(cov(Y_repeats_FF[[k]]))
  
  #BayesOpt 
  beta_optimise[[k]] <- BayesianOptimization(
    FUN = function(beta0){ebic_eval_BayesOpt(Y = lapply(Y_repeats_FF, function(df) as.matrix(df))[[k]], n, beta0, ebic.gamma = ebic.gamma, edge.tol = edge.tol, tol = 1e-6, v=5, stop_crit=1e-3)},
    bounds = list(beta0 = c(beta0_grid_min, beta0_grid_max[k])),
    init_points = 5,
    n_iter = beta0_grid_length-5,
    acq = "ucb", 
    kernel = list(type = "exponential", power = 2),
  )
  
  beta0_TLASSO_FF[k] <- beta_optimise[[k]]$Best_Par
  ebic_eval_optim_TLASSO_FF[k] <- - beta_optimise[[k]]$Best_Value
  
  #Using the optimal beta0 
  GraphicalModel[[k]] <- tlasso (Y = as.matrix(Y_repeats_FF[[k]]), beta0_TLASSO_FF[k], v = 5, stop_crit = 1e-3)
  
  Rho_hat_TLASSO_FF[[k]] <- threshold(cov2cor(pd.solve(GraphicalModel[[k]]$psi)), edge.tol)
  
}

```

Analysis

```{r Analysis, include=TRUE,echo=TRUE, eval=TRUE,cache=FALSE}

beta0_TLASSO_FF

ebic_eval_optim_TLASSO_FF

n_edges_TLASSO_FF <- rep(NA,N)
for (k in 1:N){
  n_edges_TLASSO_FF[k] <- sum(Rho_hat_TLASSO_FF[[k]][lower.tri((Rho_hat_TLASSO_FF[[k]]))] != 0)
}

```

Defining baseline (equally weighted stocks)

```{r Defining baseline, include=TRUE,echo=TRUE, eval=TRUE,cache=FALSE}

mean <- list()
for (k in 1:N){
  mean[[k]]<-colMeans(Y_repeats_FF[[k]])
}

weights_b <- list()
for (k in 1:N){
  weights_b[[k]] <- rep(1/p[k],p[k])
}

#the baseline is the target return rate for the mean variance portfolio  
baseline_portfolio <- rep(NA,N)   
for (k in 1:N){
  baseline_portfolio[k] <- sum(mean[[k]] %*% weights_b[[k]])
}

```

##Estimating Sigma with TLASSO FF

```{r estimating Sigma with TLASSO, include=TRUE,echo=TRUE, eval=TRUE,cache=FALSE}

v<-5    #degrees of freedom

Sigma_hat_TLASSO_FF <- list()
for (k in 1:N){
  Sigma_hat_TLASSO[[k]] <- (cor2cov(Rho_hat_TLASSO_FF[[k]], sigma2_vect = (apply(lapply(Y_repeats_FF, function(df) as.matrix(df))[[k]], 2, sd))^2))*(v/(v-2))
}

```

Estimating weights

```{r Weights, include=TRUE,echo=TRUE, eval=TRUE,cache=FALSE}

#minimum variance
weights_minimum_variance_TLASSO_FF <- list()
for (k in 1:N){
  weights_minimum_variance_TLASSO_FF[[k]] <- minimum_variance_portfolio(Sigma_hat_TLASSO_FF[[k]]) 
}

for (k in 1:N){
  weights_minimum_variance_TLASSO_FF[[k]] <- weights_minimum_variance_TLASSO_FF[[k]]/sum(weights_minimum_variance_TLASSO_FF[[k]])
}

#mean variance
weights_mean_variance_TLASSO_FF <- list()
for (k in 1:N){
  weights_mean_variance_TLASSO_FF[[k]] <- mvPortfolio(mean[[k]], Sigma_hat_TLASSO_FF[[k]], min.return=baseline_portfolio[k])
}

```

Estimating expected return portfolio

```{r Expected return portfolio, include=TRUE,echo=TRUE, eval=TRUE,cache=FALSE}

#minimum variance
expected_return_portfolio_minimum_variance_TLASSO_FF <- rep(NA,N)
for (k in 1:N){
  expected_return_portfolio_minimum_variance_TLASSO_FF[k] <- expected_return_portfolio_minimum_variance(Sigma_hat_TLASSO_FF[[k]], mean[[k]])
}

#mean variance
expected_return_portfolio_mean_variance_TLASSO_FF <- rep(NA,N)
for (k in 1:N){
  expected_return_portfolio_mean_variance_TLASSO_FF[k] <- sum(weights_mean_variance_TLASSO_FF[[k]]*mean[[k]])
}

```

Two portfolio solution

```{r Two portfolio solution, include=TRUE,echo=TRUE, eval=TRUE,cache=FALSE}

#it makes the expected return portfolio equal to the baseline we defined before 

W_mk <- list()
for (k in 1:N){
  one.vec <- rep(1,nrow(Sigma_hat_TLASSO_FF[[k]]))
  W_mk[[k]] <- (mean[[k]]%*%solve(Sigma_hat_TLASSO_FF[[k]]))/(as.numeric(t(one.vec[k]) %*% mean[[k]] %*% solve(Sigma_hat_TLASSO_FF[[k]])))
}

v_2PS_TLASSO_FF <- list()
for (k in 1:N){
  v_2PS_TLASSO_FF[[k]] <- weights_mean_variance_TLASSO_FF[[k]]-weights_minimum_variance_TLASSO_FF[[k]]
}

alpha_2PS_TLASSO_FF <- rep(NA,N)
for (k in 1:N){
  alpha_2PS_TLASSO_FF[k] <- ((sum(mean[[k]])/p[k])-(t(mean[[k]]) %*% weights_minimum_variance_TLASSO_FF[[k]]))/(t(mean[[k]]) %*% v_2PS_TLASSO_FF[[k]])
}

w_2PS_TLASSO_FF <- list()
for (k in 1:N){
  w_2PS_TLASSO_FF[[k]] <- weights_minimum_variance_TLASSO_FF[[k]]+(v_2PS_TLASSO_FF[[k]]*alpha_2PS_TLASSO_FF[k])
}

expected_return_portfolio_2PS_TLASSO_FF <- rep(NA,N)
for (k in 1:N){
  expected_return_portfolio_2PS_TLASSO_FF[k] <- t(mean[[k]])%*%w_2PS_TLASSO_FF[[k]]
}

```

Plot Sigma and Rho matrices

```{r Plot Sigma and Rho matrices, include=TRUE,echo=TRUE, eval=TRUE,cache=FALSE}

for (k in 1:N){
  matrixplot(Sigma_hat_TLASSO_FF[[k]]-diag(NA,p[k]))
  matrixplot(Rho_hat_TLASSO_FF[[k]]-diag(NA,p[k]))
}

```


#Actual portfolio return rate

Loading data years after

```{r Loading data years after}

start_year = 1986  #start_year we had before + 1
end_year = 2016    #end_year we had before + 1

Y_repeats_actual = list()
Y_prova = list()
k<-seq(from=1, to=length(j), by=1)
t<-seq(from=start_year, to=end_year, by=1)
for (k in 1:N){
  Y_prova[[k]]<-Y[[k]][Y[[k]]$Year == t[k],-2]  #time series with the column 'dates'
  Y_repeats_actual[[k]] = Y[[k]][Y[[k]]$Year == t[k],-(1:2)]
} 
```

TLASSO

```{r Actual portfolio return rate GLASSO}

r <- list()   #actual return rates of stocks per year
for (k in 1:N){
  r[[k]] <- colSums(Y_repeats_actual[[k]])
}

#minimum variance
portfolio_actual_return_rate_minimum_variance_TLASSO <- rep(NA,N)
for (k in 1:N){
  portfolio_actual_return_rate_minimum_variance_TLASSO[k] <- sum(weights_minimum_variance_TLASSO[[k]] * r[[k]])
}

#mean variance
portfolio_actual_return_rate_mean_variance_TLASSO <- rep(NA,N)
for (k in 1:N){
  portfolio_actual_return_rate_mean_variance_TLASSO[k] <- sum(weights_mean_variance_TLASSO[[k]] * r[[k]])
}

#cumulative actual portfolio return rate with minimum and mean variance 
sum(portfolio_actual_return_rate_minimum_variance_TLASSO)
sum(portfolio_actual_return_rate_mean_variance_TLASSO)

```

TLASSO FF

```{r Actual portfolio return rate TLASSO FF}

#minimum variance
portfolio_actual_return_rate_minimum_variance_TLASSO_FF <- rep(NA,N)
for (k in 1:N){
  portfolio_actual_return_rate_minimum_variance_TLASSO_FF[k] <- sum(weights_minimum_variance_TLASSO_FF[[k]] * r[[k]])
}

#mean variance
portfolio_actual_return_rate_mean_variance_TLASSO_FF <- rep(NA,N)
for (k in 1:N){
  portfolio_actual_return_rate_mean_variance_TLASSO_FF[k] <- sum(weights_mean_variance_TLASSO_FF[[k]] * r[[k]])
}

#cumulative actual portfolio return rate with minimum and mean variance 
sum(portfolio_actual_return_rate_minimum_variance_TLASSO_FF)
sum(portfolio_actual_return_rate_mean_variance_TLASSO_FF)

```

#Performance

Volatily

```{r Performance Volatily}

for (k in 1:N){
  row.names(Y_prova[[k]]) <- Y_prova[[k]][,1]
}

#minimum variance
daily_portfolio_return_minimum_variance_TLASSO <- list()
daily_portfolio_return_minimum_variance_TLASSO_FF <- list()

for (k in 1:31){
  daily_portfolio_return_minimum_variance_TLASSO[[k]] <- Return.portfolio(Y_prova[[k]][,2:(p[k]+1)],weights=unlist(weights_minimum_variance_TLASSO[k]), verbose=TRUE)
  daily_portfolio_return_minimum_variance_TLASSO_FF[[k]] <- Return.portfolio(Y_prova[[k]][,2:(p[k]+1)],weights=unlist(weights_minimum_variance_TLASSO_FF[k]), verbose=TRUE)
}

StdDev_minimum_variance_TLASSO <- vector()
StdDev_minimum_variance_TLASSO_FF <- vector()

for (k in 1:31){
  StdDev_minimum_variance_TLASSO[k] <- StdDev(daily_portfolio_return_minimum_variance_TLASSO[[k]]$returns)
  StdDev_minimum_variance_TLASSO_FF[k] <- StdDev(daily_portfolio_return_minimum_variance_TLASSO_FF[[k]]$returns)
}

mean(StdDev_minimum_variance_TLASSO)
mean(StdDev_minimum_variance_TLASSO_FF)

#mean variance
daily_portfolio_return_mean_variance_TLASSO <- list()
daily_portfolio_return_mean_variance_TLASSO_FF <- list()

for (k in 1:31){
  daily_portfolio_return_mean_variance_TLASSO[[k]] <- Return.portfolio(Y_prova[[k]][,2:(p[k]+1)],weights=unlist(weights_mean_variance_TLASSO[k]), verbose=TRUE)
  daily_portfolio_return_mean_variance_TLASSO_FF[[k]] <- Return.portfolio(Y_prova[[k]][,2:(p[k]+1)],weights=unlist(weights_mean_variance_TLASSO_FF[k]), verbose=TRUE)
}

StdDev_mean_variance_TLASSO <- vector()
StdDev_mean_variance_TLASSO_FF <- vector()

for (k in 1:31){
  StdDev_mean_variance_TLASSO[k] <- StdDev(daily_portfolio_return_mean_variance_TLASSO[[k]]$returns)
  StdDev_mean_variance_TLASSO_FF[k] <- StdDev(daily_portfolio_return_mean_variance_TLASSO_FF[[k]]$returns)
}

mean(StdDev_mean_variance_TLASSO)
mean(StdDev_mean_variance_TLASSO_FF)

```

Sharpe Ratio

```{r Performance Sharpe Ratio}

#minimum variance
Sharpe_ratio_minimum_variance_TLASSO <- vector()
Sharpe_ratio_minimum_variance_TLASSO_FF <- vector()

for (k in 1:N){
  row.names(Y_prova[[k]]) <- Y_prova[[k]][,1]
}

for (k in 1:N){
  Sharpe_ratio_minimum_variance_TLASSO[k] <- SharpeRatio((Y_prova[[k]][,2:(p[k]+1),drop=FALSE]), FUN= "StdDev", weights = unlist(weights_minimum_variance_TLASSO[k]))
  Sharpe_ratio_minimum_variance_TLASSO_FF[k] <- SharpeRatio((Y_prova[[k]][,2:(p[k]+1),drop=FALSE]), FUN= "StdDev", weights = unlist(weights_minimum_variance_TLASSO_FF[k]))
}

mean(Sharpe_ratio_minimum_variance_TLASSO)
mean(Sharpe_ratio_minimum_variance_TLASSO_FF)

#mean variance
Sharpe_ratio_mean_variance_TLASSO <- vector()
Sharpe_ratio_mean_variance_TLASSO_FF <- vector()

for (k in 1:N){
  Sharpe_ratio_mean_variance_TLASSO[k] <- SharpeRatio((Y_prova[[k]][,2:(p[k]+1),drop=FALSE]), FUN= "StdDev", weights = unlist(weights_mean_variance_TLASSO[k]))
  Sharpe_ratio_mean_variance_TLASSO_FF[k] <- SharpeRatio((Y_prova[[k]][,2:(p[k]+1),drop=FALSE]), FUN= "StdDev", weights = unlist(weights_mean_variance_TLASSO_FF[k]))
}

mean((Sharpe_ratio_mean_variance_TLASSO))
mean(Sharpe_ratio_mean_variance_TLASSO_FF)

```

Herfindal Index

```{r Herfindal Index}

#minimum variance
HHI_minimum_variance_TLASSO <- vector()
HHI_minimum_variance_TLASSO_FF <- vector()

for (k in 1:N){
  HHI_minimum_variance_TLASSO[k] <- HHI(unlist(weights_minimum_variance_TLASSO[[k]]))
  HHI_minimum_variance_TLASSO_FF[k] <- HHI(unlist(weights_minimum_variance_TLASSO_FF[[k]]))
}

mean(HHI_minimum_variance_TLASSO)
mean(HHI_minimum_variance_TLASSO_FF)

#mean variance
HHI_mean_variance_TLASSO <- vector()
HHI_mean_variance_TLASSO_FF <- vector()

for (k in 1:N){
  HHI_mean_variance_TLASSO[k] <- HHI(unlist(weights_mean_variance_TLASSO[[k]]))
  HHI_mean_variance_TLASSO_FF[k] <- HHI(unlist(weights_mean_variance_TLASSO_FF[[k]]))
}

mean(HHI_mean_variance_TLASSO)
mean(HHI_mean_variance_TLASSO_FF)

```
